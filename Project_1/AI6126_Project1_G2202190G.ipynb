{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vUPMePSn-fy"
   },
   "source": [
    "# Import Libraries and mount GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiCY0jxPfJVc",
    "outputId": "1165ac05-08b4-4c94-bf3e-bf257b8421ad"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.get_device_properties(device))\n",
    "!nvidia-smi\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/') # mount your drive\n",
    "%cd '/content/drive/My Drive/Notability/AI6126 Advanced Computer Vision/' \n",
    "# Above is the directory of the unzipped folder 'FashionDataset'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2_f-JuEoeHT"
   },
   "source": [
    "# Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNmDwVZGSkgV",
    "outputId": "3da1d6cf-8643-4237-d6db-665d184d8e02"
   },
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "train_names_file = \"./FashionDataset/split/train.txt\"\n",
    "train_names = np.loadtxt(train_names_file, dtype=str)\n",
    "train_names = [\"./FashionDataset/\"+name for name in train_names]\n",
    "# train_names = [name.lstrip('img/') for name in train_names]\n",
    "\n",
    "train_attr_file = \"./FashionDataset/split/train_attr.txt\"\n",
    "train_attr = np.loadtxt(train_attr_file, dtype=int)\n",
    "train_attr = torch.from_numpy(train_attr)\n",
    "num_classes = torch.max(train_attr, dim=0).values + 1 # [7, 3, 3, 4, 6, 3]\n",
    "\n",
    "class_label_count_train = np.zeros((7,6))\n",
    "for label in range(6):\n",
    "  for i in range(len(train_attr)):\n",
    "    class_label = train_attr[i,label]\n",
    "    class_label_count_train[class_label,label] += 1\n",
    "    \n",
    "print(f'Distribution in train attributes: \\n {class_label_count_train} \\n')\n",
    "\n",
    "# Val Dataset\n",
    "val_names_file = \"./FashionDataset/split/val.txt\"\n",
    "val_names = np.loadtxt(val_names_file, dtype=str)\n",
    "val_names = [\"./FashionDataset/\"+name for name in val_names]\n",
    "# val_names = [name.lstrip('img/') for name in val_names]\n",
    "\n",
    "val_attr_file = \"./FashionDataset/split/val_attr.txt\"\n",
    "val_attr = np.loadtxt(val_attr_file, dtype=int)\n",
    "val_attr = torch.from_numpy(val_attr)\n",
    "\n",
    "class_label_count_val = np.zeros((7,6))\n",
    "for label in range(6):\n",
    "  for i in range(len(val_attr)):\n",
    "    class_label = val_attr[i,label]\n",
    "    class_label_count_val[class_label,label] += 1\n",
    "    \n",
    "print(f'Distribution in val attributes: \\n {class_label_count_val} \\n')\n",
    "\n",
    "\n",
    "# Test Dataset\n",
    "test_names_file = \"./FashionDataset/split/test.txt\"\n",
    "test_names = np.loadtxt(test_names_file, dtype=str)\n",
    "test_names = [\"./FashionDataset/\"+name for name in test_names]\n",
    "# test_names = [name.lstrip('img/') for name in test_names]\n",
    "\n",
    "print(f'Number of class per label: {num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adUxIy2Kpev-"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize((320,320), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((300,300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((300,300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((300,300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class train_dataset(Dataset):\n",
    "  def __init__(self, image_dir, attr, transform=None):\n",
    "    self.attr = attr\n",
    "    self.image_dir = image_dir\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_dir)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image_path = self.image_dir[idx]\n",
    "    image = Image.open(image_path)\n",
    "    labels = self.attr[idx]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, labels\n",
    "\n",
    "class test_dataset(Dataset):\n",
    "  def __init__(self, image_dir, transform=None):\n",
    "    self.image_dir = image_dir\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_dir)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image_path = self.image_dir[idx]\n",
    "    image = Image.open(image_path)\n",
    "    # self.attr = torch.empty([len(self.images), 6], dtype=torch.int)\n",
    "    # labels = self.attr[idx]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    # return image, labels\n",
    "    return image\n",
    "\n",
    "train_data = train_dataset(train_names, train_attr, transform = train_transform)\n",
    "val_data = train_dataset(val_names, val_attr, transform = val_transform)\n",
    "test_data = test_dataset(test_names, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lS5fF0IyvLGz",
    "outputId": "24bbd948-05dc-4114-9cbd-1052c7db9e33"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32, num_workers=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32, num_workers=4, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaI7EX-Bn54g"
   },
   "source": [
    "# Define Model and Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtmhjbkpGvyG"
   },
   "outputs": [],
   "source": [
    "class ModifiedEffNet(nn.Module):\n",
    "  def __init__(self, num_classes, dropout):\n",
    "    super().__init__()\n",
    "    self.dropout = dropout\n",
    "    self.num_classes = num_classes\n",
    "\n",
    "    self.cat1_n = num_classes[0] # 7\n",
    "    self.cat2_n = num_classes[1] # 3\n",
    "    self.cat3_n = num_classes[2] # 3\n",
    "    self.cat4_n = num_classes[3] # 4\n",
    "    self.cat5_n = num_classes[4] # 6\n",
    "    self.cat6_n = num_classes[5] # 3\n",
    "\n",
    "    self.effnet = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1) # 1536 out_features\n",
    "\n",
    "    self.model_wo_fl = nn.Sequential(*(list(self.effnet.children())[:-1]))\n",
    "\n",
    "    self.cat1 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat1_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 7]\n",
    "    self.cat2 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat2_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 3]\n",
    "    self.cat3 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat3_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 3]\n",
    "    self.cat4 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat4_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 4]\n",
    "    self.cat5 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat5_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 6]\n",
    "    self.cat6 = nn.Sequential(\n",
    "        nn.Dropout(p=self.dropout),\n",
    "        nn.Linear(in_features = 1536, out_features = self.cat6_n),\n",
    "        nn.Softmax(dim=1)\n",
    "    ) # [batch size, 3]\n",
    "\n",
    "  def forward(self, x):\n",
    "    max_num_subclass = max(self.num_classes) # 7\n",
    "    x = self.model_wo_fl(x)\n",
    "    x = torch.flatten(x,1)\n",
    "    cat1 = self.cat1(x).to(device)\n",
    "    if cat1.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat1.shape[0], (max_num_subclass - cat1.shape[1])).to(device)\n",
    "      cat1 = torch.cat((cat1, filler), 1) # [batch size, 7]\n",
    "\n",
    "    cat2 = self.cat2(x).to(device)\n",
    "    if cat2.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat2.shape[0], (max_num_subclass - cat2.shape[1])).to(device)\n",
    "      cat2 = torch.cat((cat2, filler), 1) # [batch size, 7]\n",
    "\n",
    "    cat3 = self.cat3(x).to(device)\n",
    "    if cat3.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat3.shape[0], (max_num_subclass - cat3.shape[1])).to(device)\n",
    "      cat3 = torch.cat((cat3, filler), 1) # [batch size, 7]\n",
    "      \n",
    "    cat4 = self.cat4(x).to(device)\n",
    "    if cat4.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat4.shape[0], (max_num_subclass - cat4.shape[1])).to(device)\n",
    "      cat4 = torch.cat((cat4, filler), 1) # [batch size, 7]\n",
    "      \n",
    "    cat5 = self.cat5(x).to(device)\n",
    "    if cat5.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat5.shape[0], (max_num_subclass - cat5.shape[1])).to(device)\n",
    "      cat5 = torch.cat((cat5, filler), 1) # [batch size, 7]\n",
    "      \n",
    "    cat6 = self.cat6(x).to(device)\n",
    "    if cat6.shape[1] != max_num_subclass:\n",
    "      filler = torch.zeros(cat6.shape[0], (max_num_subclass - cat6.shape[1])).to(device)\n",
    "      cat6 = torch.cat((cat6, filler), 1) # [batch size, 7]\n",
    "      \n",
    "    return torch.stack([cat1, cat2, cat3, cat4, cat5, cat6], dim=2) # [batch size, 7, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFHehb_MOFwS"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  predicted_classes = torch.argmax(predictions, dim=1)\n",
    "  predictions_wrong = torch.count_nonzero(labels - predicted_classes)\n",
    "  num_predictions = torch.numel(predicted_classes)\n",
    "  predictions_correct = num_predictions - predictions_wrong\n",
    "  return predictions_correct.float() / num_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaHy06V7aNAT"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "  epoch_loss = 0.0\n",
    "  epoch_acc = 0.0\n",
    "\n",
    "  model.train()\n",
    "  for imgs, labels in dataloader:\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device) # [batch size, 6]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predictions = model(imgs) # [batch size, 7, 6]\n",
    "    loss = criterion(predictions, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    acc = accuracy(predictions, labels)\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "\n",
    "  train_loss = epoch_loss / len(train_dataloader)\n",
    "  train_acc = epoch_acc / len(train_dataloader)\n",
    "\n",
    "  return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isosdCoHbv5M"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "  epoch_loss = 0.0\n",
    "  epoch_acc = 0.0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for imgs, labels in dataloader:\n",
    "      imgs = imgs.to(device)\n",
    "      labels = labels.to(device) # [batch size, 6]\n",
    "\n",
    "      predictions = model(imgs)  # [batch size, 7, 6]\n",
    "\n",
    "      loss = criterion(predictions, labels)\n",
    "      acc = accuracy(predictions, labels)\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "  \n",
    "  val_loss = epoch_loss / len(val_dataloader)\n",
    "  val_acc = epoch_acc / len(val_dataloader)\n",
    "\n",
    "  return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv1Ei-fvn0_r"
   },
   "source": [
    "# Train Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P923XMp7PlXg",
    "outputId": "004914df-8108-436e-fa44-453c947e7082"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "LR = 0.1\n",
    "NUM_EPOCH = 50\n",
    "WEIGHT_DECAY = 0.00001\n",
    "MOMENTUM = 0.9\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# define Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Define model\n",
    "model = ModifiedEffNet(num_classes, DROPOUT)\n",
    "model = model.to(device)\n",
    "\n",
    "# Get number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters \\n')\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, NUM_EPOCH)\n",
    "\n",
    "# Define statistic variables\n",
    "stat_train_loss = []\n",
    "stat_val_loss = []\n",
    "stat_train_acc = []\n",
    "stat_val_acc = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Start model training\n",
    "print(f'Training Model:')\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Train model with train_dataset\n",
    "  train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
    "\n",
    "  # Evaluate model against val_dataset\n",
    "  val_loss, val_acc = evaluate(model, val_dataloader, criterion)\n",
    "\n",
    "  # Save model with best (smallest) val loss\n",
    "  if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    model_name = 'model.pt'\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "  end_time = time.time()\n",
    "  epoch_secs = end_time - start_time\n",
    "\n",
    "  stat_train_loss.append(train_loss)\n",
    "  stat_val_loss.append(val_loss)\n",
    "  stat_train_acc.append(train_acc)\n",
    "  stat_val_acc.append(val_acc)\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{NUM_EPOCH}: Training duration: {epoch_secs:.2f}s')\n",
    "  print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "  scheduler.step()\n",
    "\n",
    "print(f'Training Completed')\n",
    "\n",
    "# Plot training Curves\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,16))\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss vs Epoch')\n",
    "ax1.plot(stat_train_loss, 'ro-', label='Train')\n",
    "ax1.plot(stat_val_loss, 'bo-', label='Val')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy vs Epoch')\n",
    "ax2.plot(stat_train_acc, 'ro-', label='Train')\n",
    "ax2.plot(stat_val_acc, 'bo-', label='Val')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "predictions = torch.Tensor().to(device)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for imgs in test_dataloader:\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    pred = model(imgs) # [batch size, 7, 6]\n",
    "    pred = torch.argmax(pred,dim=1) # [batch size, 6]\n",
    "\n",
    "    predictions = torch.cat((predictions, pred), 0) # [1000, 6]\n",
    "\n",
    "# Save Prediction    \n",
    "predictions = predictions.cpu().numpy()\n",
    "predictions = predictions.astype(int)\n",
    "file_name = 'prediction.txt' \n",
    "np.savetxt(file_name, predictions, fmt='%.1d')\n",
    "print('Done \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBrS_3fXefTj",
    "outputId": "4df452c7-5572-42ef-eca4-b0cde46d324a"
   },
   "outputs": [],
   "source": [
    "## Run the next 2 lines if the model was NOT defined and trained before\n",
    "# model = ModifiedEffNet(num_classes, 0.2)\n",
    "# model = model.to(device)\n",
    "\n",
    "model_name_temp = 'model_LR0.1_EPOCH50_B32_WD1e-5.pt'\n",
    "model.load_state_dict(torch.load(model_name_temp))\n",
    "model.eval()\n",
    "\n",
    "predictions = torch.Tensor().to(device) # Initialize blank tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "  for imgs in test_dataloader:\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    pred = model(imgs) # [batch size, 7, 6]\n",
    "    pred = torch.argmax(pred,dim=1) # [batch size, 6]\n",
    "\n",
    "    predictions = torch.cat((predictions, pred), 0) # [1000, 6]\n",
    "\n",
    "predictions = predictions.cpu().numpy()\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "## Run next 2 lines only if want to save the predictions as a .txt file\n",
    "# file_name = 'prediction.txt' \n",
    "# np.savetxt(file_name, predictions, fmt='%.1d')\n",
    "\n",
    "print('Done \\n')\n",
    "\n",
    "# Load results\n",
    "previous_saved_pred = \"prediction_LR0.1_EPOCH50_B32_WD1e-5.txt\"\n",
    "previous_saved_pred = np.loadtxt(previous_saved_pred, dtype=int)\n",
    "\n",
    "# Compare loaded results with predictions from saved model, output should be 0\n",
    "num_different_pred = np.count_nonzero((predictions - previous_saved_pred))\n",
    "print(num_different_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
